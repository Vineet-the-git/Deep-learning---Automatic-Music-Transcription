{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN Preprocessing Mel Transform.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lo2yaGWKSEjU"
      },
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import pretty_midi \n",
        "pretty_midi.pretty_midi.MAX_TICK = 1e10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHIiHXqTSLtr"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rf2ReQMSfXu"
      },
      "source": [
        "#preparing the data from the original audio files\n",
        "entries = os.scandir('/content/drive/MyDrive/train_source')#loading the data to process which we are going to use for training \n",
        "os.mkdir('/content/drive/MyDrive/trainfiles')\n",
        "os.mkdir('/content/drive/MyDrive/trainfiles/trainwav')\n",
        "os.mkdir('/content/drive/MyDrive/trainfiles/trainmid')\n",
        "\n",
        "for file in entries:\n",
        "    file_name,file_extensions=os.path.splitext(file)\n",
        "\n",
        "    if file_extensions=='.wav':\n",
        "        y, sr = librosa.load(file)\n",
        "        sr=16000\n",
        "        hop_length = 512 # number of samples that we 'hopped' over\n",
        "        n_fft = 2048 # window 'size'\n",
        "        MFCC = librosa.feature.mfcc(y, sample_rate = sr, n_fft=n_fft, hop_length=hop_length, n_mfcc=13)\n",
        "        #using the librosa library to create the Mel Spetrogram\n",
        "        Mel = librosa.amplitude_to_db(MFCC)  # taking the amplitude on logarithmic scale gives a better visualization of data\n",
        "        b=np.shape(Mel)[1]\n",
        "        c=len(y) # it is being stored because it will be used for the frequency while making the piano roll file\n",
        "        out = '/content/drive/MyDrive/trainfiles/trainwav/wav_'+str(file_name[40:])+'.npy'\n",
        "        print(np.shape(Mel))\n",
        "        np.save(out,Mel)\n",
        "        print('wrote file', out)\n",
        "        entries1 = os.scandir('/content/drive/MyDrive/train_source')#it is being loaded again so that we can get the corresponding midi file to the wav file which we have just used\n",
        "\n",
        "        for file1 in entries1:\n",
        "          file_name1,file_extensions1=os.path.splitext(file1)\n",
        "\n",
        "          if file_name1==file_name and file_extensions1==\".mid\":\n",
        "            file2=file_name + file_extensions1\n",
        "            pm = pretty_midi.PrettyMIDI(file2)\n",
        "            a=pm.instruments[0].get_piano_roll(float(sr*float(b)/float(c)))# The frequency has been taken such that its shape and the cqt files shape is same \n",
        "            a=np.append(np.transpose(a), np.zeros((b-np.shape(a)[1],128)), axis=0)\n",
        "            a=np.transpose(a)\n",
        "            print(np.shape(a))\n",
        "            out = '/content/drive/MyDrive/trainfiles/trainmid/mid_'+str(file_name1[40:])+'mid'+'.npy'\n",
        "            np.save(out,a)\n",
        "            print(\"saving\", out)\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}